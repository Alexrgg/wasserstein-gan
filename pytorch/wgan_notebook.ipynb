{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "from ignite.engine.engine import Events, Engine\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "from model import get_critic, get_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfiniteDataLoader:\n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.data_loader.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.iterator = iter(self.data_loader)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            batch = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.data_loader)\n",
    "            batch = next(self.iterator)\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANTrainer:\n",
    "    def __init__(self, data_loader, gen: nn.Module, cri: nn.Module,\n",
    "                 opt_g, opt_c, n_cri, gp_lam: float, device):\n",
    "\n",
    "        assert len(n_cri) == 2\n",
    "\n",
    "        self.data_loader = data_loader\n",
    "        self.gen = gen\n",
    "        self.cri = cri\n",
    "        self.opt_g = opt_g\n",
    "        self.opt_c = opt_c\n",
    "        self.n_cri = n_cri\n",
    "        self.gp_lam = gp_lam\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, engine, batch):\n",
    "        # 複数回サンプリングする必要があるため渡されたbatchは使わない\n",
    "        # データはself.data_loaderから取得\n",
    "\n",
    "        self.gen.train()\n",
    "        self.cri.train()\n",
    "\n",
    "        # update critic\n",
    "        iter_num = engine.state.iteration\n",
    "        upd_num = self.n_cri[1] if iter_num <= 25 or iter_num % 500 == 0 else self.n_cri[0]\n",
    "        critic_mean_loss = 0\n",
    "        i = 0\n",
    "        for batch in self.data_loader:\n",
    "            x_real, _ = batch\n",
    "            x_real = x_real.to(self.device)\n",
    "\n",
    "            z = np.random.uniform(size=(self.data_loader.batch_size, Z_DIM)).astype(np.float32)\n",
    "            z = torch.from_numpy(z).to(self.device)\n",
    "            x_fake = self.gen(z).detach()\n",
    "            x_fake.requires_grad = True\n",
    "\n",
    "            cri_loss = (self.cri(x_fake) - self.cri(x_real)).mean()  # Wasserstein距離の逆符号\n",
    "\n",
    "            # gradient penalty\n",
    "            eps = np.random.uniform(size=(self.data_loader.batch_size, 1, 1, 1)).astype(np.float32)\n",
    "            eps = torch.from_numpy(eps).to(self.device)\n",
    "            x_fusion = eps * x_real + (1 - eps) * x_fake  # (N,1,H,W)\n",
    "            g_critic = torch.autograd.grad(torch.unbind(self.cri(x_fusion)), x_fusion, create_graph=True)[0]  # (N,1,H,W)\n",
    "            gp = g_critic.square().sum(dim=(1, 2, 3)).sqrt()\n",
    "            gp = (gp - 1).square().mean()\n",
    "\n",
    "            total_loss = cri_loss + self.gp_lam * gp\n",
    "\n",
    "            self.opt_c.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.opt_c.step()\n",
    "\n",
    "            critic_mean_loss += total_loss.item()\n",
    "\n",
    "            i += 1\n",
    "            if i >= upd_num:\n",
    "                break\n",
    "\n",
    "        critic_mean_loss /= upd_num # equivalente a: critic_mean_loss = critic_mean_loss / upd_num\n",
    "\n",
    "        # update generator\n",
    "        z = np.random.uniform(size=(self.data_loader.batch_size, Z_DIM)).astype(np.float32)\n",
    "        z = torch.from_numpy(z).to(self.device)\n",
    "        x_fake = self.gen(z)\n",
    "        gen_loss = -self.cri(x_fake).mean()\n",
    "\n",
    "        self.opt_c.zero_grad()\n",
    "        self.opt_g.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        self.opt_g.step()\n",
    "\n",
    "        return {\n",
    "            \"critic_loss\": critic_mean_loss,\n",
    "            \"generator_loss\": gen_loss.item()\n",
    "        }\n",
    "\n",
    "\n",
    "class MetricsAccumulator:\n",
    "    def __init__(self, keys: list):\n",
    "        self.keys = keys\n",
    "        self.logs = {k: 0.0 for k in keys}\n",
    "        self.num = 0\n",
    "\n",
    "    def __call__(self, engine):\n",
    "        for k in self.keys:\n",
    "            self.logs[k] += engine.state.output[k]\n",
    "        self.num += 1\n",
    "\n",
    "    def get_mean(self, key):\n",
    "        return self.logs[key] / self.num\n",
    "\n",
    "    def reset(self):\n",
    "        self.logs = {k: 0.0 for k in self.keys}\n",
    "        self.num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_metrics(log_dict: dict, accumulator: MetricsAccumulator, keys: list = None):\n",
    "    if keys is None:\n",
    "        keys = accumulator.keys\n",
    "\n",
    "    def _record(engine):\n",
    "        _add(\"iteration\", engine.state.iteration)\n",
    "\n",
    "        for k in keys:\n",
    "            _add(k, accumulator.get_mean(k))\n",
    "\n",
    "        accumulator.reset()\n",
    "\n",
    "    def _add(key, value):\n",
    "        if key in log_dict:\n",
    "            log_dict[key].append(value)\n",
    "        else:\n",
    "            log_dict[key] = [value]\n",
    "\n",
    "    return _record\n",
    "\n",
    "\n",
    "def plot_metrics(log_dict: dict, x_key: str, y_keys: list, out_path: Path):\n",
    "    def _plot(engine):\n",
    "        plt.figure()\n",
    "        for k in y_keys:\n",
    "            plt.plot(log_dict[x_key], log_dict[k], label=k)\n",
    "        plt.legend()\n",
    "        plt.xlabel(x_key)\n",
    "        plt.savefig(str(out_path))\n",
    "        plt.close()\n",
    "\n",
    "    return _plot\n",
    "\n",
    "\n",
    "def print_metrics(log_dict: dict, keys: list):\n",
    "    return lambda engine: print(\", \".join(f\"{k}: {log_dict[k][-1]}\" for k in keys))\n",
    "\n",
    "\n",
    "def save_img(generator: nn.Module, out_dir_path: Path, device):\n",
    "    try:\n",
    "        out_dir_path.mkdir(parents=True)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    def _save(engine):\n",
    "        z = np.random.uniform(size=(1, Z_DIM)).astype(np.float32)\n",
    "        z = torch.from_numpy(z).to(device)\n",
    "\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            x = generator(z).detach().cpu().numpy().squeeze() * 255\n",
    "\n",
    "        p = out_dir_path / f\"out_iter_{engine.state.iteration:05d}.png\"\n",
    "        cv2.imwrite(str(p), x.astype(np.uint8))\n",
    "\n",
    "    return _save\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM = 30\n",
    "def main(args):\n",
    "    # Adaptado para usar aceleración en MacOS\n",
    "    if args.g >= 0:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(f\"cuda:{args.g:d}\")\n",
    "            print(f\"GPU CUDA mode: {args.g:d}\")\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "            print(f\"GPU mps for MacOS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CPU mode\")\n",
    "\n",
    "    result_dir = Path(args.result_dir)\n",
    "\n",
    "    # MNISTデータ取得\n",
    "    mnist_train = MNIST(root=\".\", download=True, train=True,\n",
    "                        transform=lambda x: np.expand_dims(np.asarray(x, dtype=np.float32), 0) / 255)\n",
    "    mnist_loader = DataLoader(mnist_train, args.batchsize)\n",
    "    mnist_loader = InfiniteDataLoader(mnist_loader)\n",
    "\n",
    "    generator = get_generator(Z_DIM).to(device)\n",
    "    critic = get_critic().to(device)\n",
    "\n",
    "    opt_g = Adam(generator.parameters(), args.alpha, (args.beta1, args.beta2))\n",
    "    opt_c = Adam(critic.parameters(), args.alpha, (args.beta1, args.beta2))\n",
    "\n",
    "    trainer = Engine(WGANTrainer(mnist_loader, generator, critic, opt_g, opt_c,\n",
    "                                 args.n_cri, args.gp_lam, device))\n",
    "\n",
    "    log_dict = {}\n",
    "    accumulator = MetricsAccumulator([\"generator_loss\", \"critic_loss\"])\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED, accumulator)\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(every=500), record_metrics(log_dict, accumulator))\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(every=500), print_metrics(log_dict, accumulator.keys))\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(every=500),\n",
    "                              plot_metrics(log_dict, \"iteration\", accumulator.keys, result_dir / \"metrics.pdf\"))\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(every=500), save_img(generator, result_dir / \"generated_samples\", device))\n",
    "\n",
    "    # 指定されたイテレーション数で終了させる\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(once=args.iteration), lambda engine: engine.terminate())\n",
    "\n",
    "    trainer.run(mnist_loader, max_epochs=10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001,\n",
      " 'batchsize': 64,\n",
      " 'beta1': 0.5,\n",
      " 'beta2': 0.9,\n",
      " 'g': 1,\n",
      " 'gp_lam': 10.0,\n",
      " 'iteration': 199000,\n",
      " 'n_cri': [5, 100],\n",
      " 'result_dir': 'result'}\n",
      "GPU mps for MacOS\n",
      "generator_loss: 0.7859628632441163, critic_loss: -4.550230452510714\n",
      "generator_loss: 0.29959071191214026, critic_loss: -1.4116484018605948\n",
      "generator_loss: 2.082116430431604, critic_loss: -1.193415075558424\n",
      "generator_loss: 3.4949639447331426, critic_loss: -1.2989082745870948\n",
      "generator_loss: 5.341739231109619, critic_loss: -1.4048410435667635\n",
      "generator_loss: 6.520712934494019, critic_loss: -1.45491073954627\n",
      "generator_loss: 7.228562222003937, critic_loss: -1.5091009885473532\n",
      "generator_loss: 7.551783550262451, critic_loss: -1.569752344903201\n",
      "generator_loss: 7.399528996944428, critic_loss: -1.6239706043985478\n",
      "generator_loss: 7.174618826389313, critic_loss: -1.6538480126886064\n",
      "generator_loss: 7.287543992996216, critic_loss: -1.6591238124606005\n",
      "generator_loss: 7.086586984634399, critic_loss: -1.7106633759170773\n",
      "generator_loss: 7.470729793548584, critic_loss: -1.732458633023426\n",
      "generator_loss: 8.110004279136657, critic_loss: -1.7553175195626916\n",
      "generator_loss: 8.132543073654174, critic_loss: -1.7576255612163998\n",
      "generator_loss: 7.802639798164368, critic_loss: -1.7834237439261365\n",
      "generator_loss: 7.4811368703842165, critic_loss: -1.7992670656280223\n",
      "generator_loss: 6.698582623720169, critic_loss: -1.825476379450113\n",
      "generator_loss: 6.216571691989898, critic_loss: -1.8445657554051302\n",
      "generator_loss: 5.5342642669677735, critic_loss: -1.8518854634225392\n",
      "generator_loss: 5.877115240335464, critic_loss: -1.8664072158080343\n",
      "generator_loss: 6.021279523849487, critic_loss: -1.878338482364714\n",
      "generator_loss: 5.9091985545158385, critic_loss: -1.901589783560634\n",
      "generator_loss: 5.880213334083557, critic_loss: -1.9024687988384075\n",
      "generator_loss: 5.688057318687439, critic_loss: -1.9112855813448122\n",
      "generator_loss: 5.365266892433167, critic_loss: -1.9337971459764247\n",
      "generator_loss: 4.991892492771148, critic_loss: -1.9428877801771465\n",
      "generator_loss: 4.832219881892204, critic_loss: -1.9541734512552604\n",
      "generator_loss: 4.635161680102349, critic_loss: -1.9651142539709066\n",
      "generator_loss: 4.45268332362175, critic_loss: -1.9703151653993138\n",
      "generator_loss: 4.169513721629977, critic_loss: -1.984301989128293\n",
      "generator_loss: 3.9870174882411957, critic_loss: -1.9868729299315822\n",
      "generator_loss: 3.8467351517677306, critic_loss: -2.0000665827576802\n",
      "generator_loss: 3.6521965376883747, critic_loss: -2.0089943288698793\n",
      "generator_loss: 3.397836705066264, critic_loss: -2.016440660519301\n",
      "generator_loss: 3.2583466875515876, critic_loss: -2.024367374278904\n",
      "generator_loss: 3.1828456136733294, critic_loss: -2.039610232254566\n",
      "generator_loss: 3.1272400980442763, critic_loss: -2.0451911872582134\n",
      "generator_loss: 2.8089259375333784, critic_loss: -2.059972133918108\n",
      "generator_loss: 2.3631228948831557, critic_loss: -2.064581723895892\n",
      "generator_loss: 2.2140885283350946, critic_loss: -2.0811088396367414\n",
      "generator_loss: 2.3204101093411444, critic_loss: -2.0961807334838793\n",
      "generator_loss: 2.26389905500412, critic_loss: -2.117041508579254\n",
      "generator_loss: 2.016977089289576, critic_loss: -2.1407699307732275\n",
      "generator_loss: 2.0232745646983386, critic_loss: -2.1476749827837947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m args_aux \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args(args\u001b[39m=\u001b[39m[])\n\u001b[1;32m     29\u001b[0m pprint\u001b[39m.\u001b[39mpprint(\u001b[39mvars\u001b[39m(args_aux))\n\u001b[0;32m---> 30\u001b[0m main(args_aux)\n",
      "Cell \u001b[0;32mIn[33], line 44\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m# 指定されたイテレーション数で終了させる\u001b[39;00m\n\u001b[1;32m     42\u001b[0m trainer\u001b[39m.\u001b[39madd_event_handler(Events\u001b[39m.\u001b[39mITERATION_COMPLETED(once\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39miteration), \u001b[39mlambda\u001b[39;00m engine: engine\u001b[39m.\u001b[39mterminate())\n\u001b[0;32m---> 44\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(mnist_loader, max_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m data\n\u001b[1;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run()\n\u001b[1;32m    893\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    934\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run_generator)\n\u001b[1;32m    936\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m out:\n\u001b[1;32m    937\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEngine run is terminating due to exception: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(e)\n\u001b[1;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 959\u001b[0m epoch_time_taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    961\u001b[0m \u001b[39m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimes[Events\u001b[39m.\u001b[39mEPOCH_COMPLETED\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/ignite/engine/engine.py:1068\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1066\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_function(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mbatch)\n\u001b[1;32m   1069\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1070\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[0;32mIn[31], line 50\u001b[0m, in \u001b[0;36mWGANTrainer.__call__\u001b[0;34m(self, engine, batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m total_loss \u001b[39m=\u001b[39m cri_loss \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgp_lam \u001b[39m*\u001b[39m gp\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_c\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 50\u001b[0m total_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_c\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     53\u001b[0m critic_mean_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/wasserstein-gan/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "## Modificados parámetros por defecto a los de PassGAN paper [1]\n",
    "#   Falta determinar lo que definen en el paper como:\n",
    "#   + Number of discriminator iterations per generator iteration: 10\n",
    "#   + Model dimensionality (Dimensionalidad de cada una de las 5 Redes Residuales): 128\n",
    "#   + Verificar que hay 5 redes residuales!!!\n",
    "#   + Output sequence: 10 characters\n",
    "#   + Size input noise: 128 floting point numbers\n",
    "#   + Max nº examples: size of entire dataset\n",
    "#   \n",
    "#   \n",
    "#   Del wgan.py falta determinar que son los parámetro: \n",
    "#   - gp_lam: gradient penalty lamda? --> + Gradient penalty coefficient (λ): 10\n",
    "#   - g: si se usa GPU o no. 1 se usa si esta disponible.\n",
    "#   - n_cri\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"WGAN(-GP)\")\n",
    "parser.add_argument(\"-b\", \"--batchsize\", type=int, default=64) #ok\n",
    "parser.add_argument(\"-i\", \"--iteration\", type=int, default=199000) #ok\n",
    "parser.add_argument(\"--alpha\", type=float, default=10**-4) #ok\n",
    "parser.add_argument(\"--beta1\", type=float, default=0.5) #ok\n",
    "parser.add_argument(\"--beta2\", type=float, default=0.9) #ok\n",
    "parser.add_argument(\"--n_cri\", type=int, nargs=2, default=[5, 100])\n",
    "parser.add_argument(\"--gp_lam\", type=float, default=10.0) #ok\n",
    "parser.add_argument(\"-g\", type=int, default=1, help=\"GPU ID (negative value indicates CPU mode)\")\n",
    "parser.add_argument(\"--result_dir\", default=\"result\")\n",
    "args_aux = parser.parse_args(args=[])\n",
    "pprint.pprint(vars(args_aux))\n",
    "main(args_aux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wasserstein-gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d15d07db5e465091009b5a6019f70af0cb3b4a200ba3697cb87e4c94de726c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
